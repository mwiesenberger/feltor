<!-- HTML header for doxygen 1.9.3-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Discontinuous Galerkin Library: MPI Distributed Gather and Scatter</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
    <!-- ... doxygen-awesome Fragment copy ... -->
    <script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
    <script type="text/javascript">
        DoxygenAwesomeFragmentCopyButton.init()
    </script>
    <!-- ... End doxygen-awesome Fragment copy ... -->
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
window.MathJax = {
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-fragment-copy-button.js" rel="stylesheet" type="text/css"/>
<link href="menubar.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Make a nice link to github (copied from doxygen-awesome/doxygen-custom/header.html-->
<!-- https://tholman.com/github-corners/ -->
<a href="https://github.com/feltor-dev/feltor" class="github-corner" title="View source on GitHub" target="_blank">
    <svg viewBox="0 0 250 250" width="80" height="80" style="position: absolute; top: 0; border: 0; right: 0; z-index: 99;" aria-hidden="true">
    <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<!-- End Make a nice link to github -->
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
    <!--My own title area-->
  <ul class="menubar">
      <!-- <li><a href="../../../index.html">/</a><li>-->
    <li><a href="../../dg/html/topics.html">dg</a></li>
    <li><a href="../../geometries/html/topics.html">dg::geo</a></li>
    <li><a href="../../file/html/topics.html">dg::file</a></li>
    <li><a href="../../exblas/html/namespacedg_1_1exblas.html">dg::exblas</a></li>
    <li><a href="../../matrix/html/topics.html">dg::mat</a></li>
  </ul>
  <!--End My own title area-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Discontinuous Galerkin Library
   </div>
   <div id="projectbrief">#include &quot;dg/algorithm.h&quot;</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('group__mpi__comm.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">MPI Distributed Gather and Scatter<div class="ingroups"><a class="el" href="group__level1.html">Level 1: Vectors, Matrices and basic operations</a> &raquo; <a class="el" href="group__mpi__structures.html">MPI backend</a></div></div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Collaboration diagram for MPI Distributed Gather and Scatter:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__mpi__comm.svg" width="334" height="51"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structdg_1_1_m_p_i_gather.html">dg::MPIGather&lt; Vector &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimized MPI Gather operation.  <a href="structdg_1_1_m_p_i_gather.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structdg_1_1_m_p_i_kronecker_gather.html">dg::MPIKroneckerGather&lt; Vector &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Communicator for asynchronous communication of <code><a class="el" href="structdg_1_1_m_p_i_sparse_block_mat.html" title="Distributed memory Sparse block matrix class, asynchronous communication.">MPISparseBlockMat</a></code>.  <a href="structdg_1_1_m_p_i_kronecker_gather.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gaa0178080d1fb8f066a28e28e3b1465e1" id="r_gaa0178080d1fb8f066a28e28e3b1465e1"><td class="memTemplParams" colspan="2">template&lt;class MessageType &gt; </td></tr>
<tr class="memitem:gaa0178080d1fb8f066a28e28e3b1465e1"><td class="memTemplItemLeft" align="right" valign="top">std::map&lt; int, MessageType &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a> (const std::map&lt; int, MessageType &gt; &amp;messages, MPI_Comm comm)</td></tr>
<tr class="memdesc:gaa0178080d1fb8f066a28e28e3b1465e1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exchange messages between processes in a communicator.  <br /></td></tr>
<tr class="separator:gaa0178080d1fb8f066a28e28e3b1465e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga05dfb8393768dc9fe68f8ae1baca2b68" id="r_ga05dfb8393768dc9fe68f8ae1baca2b68"><td class="memTemplParams" colspan="2">template&lt;class ContainerType &gt; </td></tr>
<tr class="memitem:ga05dfb8393768dc9fe68f8ae1baca2b68"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ga05dfb8393768dc9fe68f8ae1baca2b68">dg::mpi_gather</a> (const thrust::host_vector&lt; std::array&lt; int, 2 &gt; &gt; &amp;gather_map, const ContainerType &amp;gatherFrom, ContainerType &amp;result, MPI_Comm comm)</td></tr>
<tr class="memdesc:ga05dfb8393768dc9fe68f8ae1baca2b68"><td class="mdescLeft">&#160;</td><td class="mdescRight">Un-optimized distributed gather operation.  <br /></td></tr>
<tr class="separator:ga05dfb8393768dc9fe68f8ae1baca2b68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7d13f26508e562519924d5c5950222c8" id="r_ga7d13f26508e562519924d5c5950222c8"><td class="memTemplParams" colspan="2">template&lt;class ContainerType &gt; </td></tr>
<tr class="memitem:ga7d13f26508e562519924d5c5950222c8"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ga7d13f26508e562519924d5c5950222c8">dg::mpi_scatter</a> (const thrust::host_vector&lt; std::array&lt; int, 2 &gt; &gt; &amp;scatter_map, const ContainerType &amp;toScatter, ContainerType &amp;result, MPI_Comm comm, bool resize_result=false)</td></tr>
<tr class="memdesc:ga7d13f26508e562519924d5c5950222c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Un-optimized distributed scatter operation.  <br /></td></tr>
<tr class="separator:ga7d13f26508e562519924d5c5950222c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga653c6729a09cef2106ef16e780e42a77" id="r_ga653c6729a09cef2106ef16e780e42a77"><td class="memTemplParams" colspan="2">template&lt;class Integer &gt; </td></tr>
<tr class="memitem:ga653c6729a09cef2106ef16e780e42a77"><td class="memTemplItemLeft" align="right" valign="top">thrust::host_vector&lt; std::array&lt; Integer, 2 &gt; &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="#ga653c6729a09cef2106ef16e780e42a77">dg::mpi_invert_permutation</a> (const thrust::host_vector&lt; std::array&lt; Integer, 2 &gt; &gt; &amp;p, MPI_Comm comm)</td></tr>
<tr class="memdesc:ga653c6729a09cef2106ef16e780e42a77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Invert a globally bijective index map.  <br /></td></tr>
<tr class="separator:ga653c6729a09cef2106ef16e780e42a77"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<h1><a class="anchor" id="mpigather"></a>
MPI distributed gather and scatter operations</h1>
<p>In order to understand what this is about you should first really(!) understand what gather and scatter operations are, so grab pen and paper! </p><dl class="section note"><dt>Note</dt><dd>The dg library only implements optimized MPI gather operations. There is an un-optimized <code><a class="el" href="#ga7d13f26508e562519924d5c5950222c8" title="Un-optimized distributed scatter operation.">dg::mpi_scatter</a></code> though. The reason is that gather operations are more easy to understand and implement because of the possible reduction in scatter operations. </dd></dl>
<h2><a class="anchor" id="primer"></a>
Primer: Gather and scatter operations</h2>
<p>First, we note that gather and scatter are most often used in the context of memory buffers. The buffer needs to be filled wih values (gather) or these values need to be written back into the original place (scatter).</p>
<p>Imagine a buffer vector w and an index map \( \text{g}[i]\) that gives to every index \( i\) in this vector w an index \( \text{g}[i]\) into a source vector v.</p>
<p>We can now define: <b>Gather</b> values from v and put them into w according to \( w[i] = v[\text{g}[i]] \)</p>
<p>Loosely we think of <b>Scatter</b> as the reverse operation, i.e. take the values in w and write them back into v. However, simply writing \( v[\text{g}[j]] = w[j] \) is a very <b>bad</b> definition. What should happen if \( g[j] = g[k]\) for some j and k? What if some indices \( v_i\) are not mapped at all?</p>
<p>It is more accurate to represent the gather and scatter operation by a matrix.</p>
<p><b>Gather</b> matrix: A matrix \( G\) of size \( m \times N\) is a gather matrix if it consists of only 1's and 0's and has exactly one "1" in each row. \( m\) is the buffer size, \( N \) is the vector size and \( N\) may be smaller, same or larger than \(m\). If \( \text{g}[i]\) is the index map then </p><p class="formulaDsp">
\[ G_{ij} := \delta_{\text{g}[i] j}\]
</p>
<p> We have \( w = G v\)</p>
<p><b>Scatter</b> matrix: A matrix \( S \) is a scatter matrix if its transpose is a gather matrix.</p>
<p>This means that \( S\) has size \( N \times m \) consists of only 1's and 0's and has exactly one "1" in each column. If \( \text{g}[j]\) is the index map then </p><p class="formulaDsp">
\[ S_{ij} := \delta_{i \text{g}[j]}\]
</p>
<p> We have \( v = S w\)</p>
<p>All of the following statements are true</p>
<ul>
<li>The transpose of a gather matrix is a scatter matrix \( S  = G^\mathrm{T}\). The associated index map of \( S\) is identical to the index map of \( G\).</li>
<li>The transpose of a scatter matrix is a gather matrix \( G  = S^\mathrm{T}\). The associated index map of \( G\) is identical to the index map of \( S\).</li>
<li>From a given index map we can construct two matrices ( \( G \) and \( S\))</li>
<li>A simple consistency test is given by \( (Gv)\cdot (Gv) = S(Gv)\cdot v\).</li>
<li>A scatter matrix can have zero, one or more "1"s in each row.</li>
<li>A gather matrix can have zero, one or more "1"s in each column.</li>
<li>If v is filled with its indices i.e. \( v_i = i\) then \( m = Gv\) i.e. the gather operation reproduces the index map</li>
<li>If the entries of w are \( w_j = j\) then \( m \neq Sw\) does <b>not</b> reproduce the index map</li>
<li>In a "coo" formatted sparse matrix format the gather matrix is assembled via: \( m \) rows, \( N\) columns and \( m\) non-zeroes, the values array would consist only of "1"s, the row array is just the index \(i\) and the column array is the map \( g[i]\).</li>
<li>In a "coo" formatted sparse matrix format the scatter matrix is assembled via: \( N \) rows, \( m\) columns and \( m\) non-zeroes, the values array would consist only of "1"s, the row array is the map \(g[j]\) and the column array is the index \( j\).</li>
<li>\( G&#39; = G_1 G_2 \), i.e. the multiplication of two gather matrices is again a gather</li>
<li>\( S&#39; = S_1 S_2 \), i.e. the multiplication of two scatter matrices is again a scatter</li>
</ul>
<p>Of the scatter and gather matrices permutations are especially interesting A matrix is a <b>permutation</b> if and only if it is both a scatter and a gather matrix. In such a case it is square \( m \times m\) and </p><p class="formulaDsp">
\[ P^{-1} = P^T\]
</p>
<p>. The buffer \( w\) and vector \( v\) have the same size \(m\).</p>
<p>The following statements are all true</p><ul>
<li>The index map of a permutation is bijective i.e. invertible i.e. each element of the source vector v maps to exactly one location in the buffer vector w.</li>
<li>The scatter matrix \( S = G^T \equiv G&#39;\neq G\) is a gather matrix (in general unequal \( G\)) with the associate index map \( m^{-1}\). Since the index map is recovered by applying the gather operation to the vector containing its index as values, we have <p class="formulaDsp">
\[ m^{-1} = G&#39; \vec i = S \vec i\]
</p>
</li>
<li>\( S&#39; = P_1 S P_2 \), i.e. multiplication of a scatter matrix by a permutation is again a scatter matrix</li>
<li>\( G&#39; = P_1 G P_2 \), i.e. multiplication of a gather matrix by a permutation is again a gather matrix</li>
<li>A Permutation is <b>symmetric</b> if and only if it has identical scatter and gather maps</li>
<li>Symmetric permutations can be implemented "in-place" i.e. the source and buffer can be identical</li>
</ul>
<h2><a class="anchor" id="mpi_dist_gather"></a>
MPI distributed gather and scatter</h2>
<p>Now we turn the case that v and w are distributed across processes. Accordingly, the index map \( g\) is also distributed across processes (in the same way w is). The elements of \( g\) are <b>global</b> indices into v that have to be transformed to pairs </p><p class="formulaDsp">
\[ i = [r, j]\]
</p>
<p> where j is the local index into v and r is the rank in communicator) according to a user provided function. The user has to provide the index map as vector of mentioned pairs.</p>
<p>Imagine now that we want to perform a globally distributed gather operation. Notice that there a <b>Bootstrap</b> problem involved. The given index map tells each rank from where to receive data but each rank also needs to know where to send its own data to. This means in order to setup the communication we need to communicate to start with (the <code><a class="el" href="#gaa0178080d1fb8f066a28e28e3b1465e1" title="Exchange messages between processes in a communicator.">dg::mpi_permute</a></code> function does that):</p><ul>
<li>From the given index map a MPI communication matrix (of size \( s \times s\) where \( s\) is the number of processes in the MPI communicator) can be inferred. Each row shows how many elements a given rank ( the row index) receives from each of the other ranks in the communicator (the column indices). Each column of this map describe the sending pattern, i.e. how many elements a given rank (the column index) has to send each of the other ranks in the communicator. If the MPI communication matrix is symmetric we can perform MPI communications <b>in-place</b></li>
<li>The information from the communication matrix can be used to allocate appropriately sized MPI send and receive buffers. Furthermore, it is possible to define a <b>permutation</b> across different processes. It is important to note that the index map associated to that permutation is immplementation defined i.e. the implementation analyses the communication matrix and chooses an optimal call of MPI Sends and Recvs. The implementation then provides two index maps. The first one must be used to gather values from v into the MPI send buffer and the second one can be used to gather values from the receive buffer into the target buffer. Notice that these two operations are <b>local</b> and require no MPI communication.</li>
</ul>
<p>In total we thus describe the global gather as </p><p class="formulaDsp">
\[ w = G v = G_1 P_{G,MPI} G_2 v\]
</p>
<p>The global scatter operation is then simply </p><p class="formulaDsp">
\[ v = S w = G_2^T P^T_{G,MPI} G^T_1 w = S_2 P_{S,MPI} S_1 w \]
</p>
<p> (The scatter operation is constructed the same way as the gather operation, it is just the execution that is different)</p>
<dl class="section note"><dt>Note</dt><dd>If the scatter/gather operations are part of a matrix-vector multiplication then \( G_1\) or \( S_1\) can be absorbed into the matrix</dd></dl>
<p class="formulaDsp">
\[ M v = R G v  = R G_1 P_{G,MPI} G_2 v = R&#39; P_{G,MPI} G_2 v\]
</p>
<p>. If R was a coo matrix the simple way to obtain R' is replacing the column indices with the map \( g_1\). </p><dl class="section note"><dt>Note</dt><dd>To give the involved vectors unique names we call v the "vector", \( s = G_2 v\) is the "store" and, \( b = P s\) is the "buffer".</dd></dl>
<p>For </p><p class="formulaDsp">
\[ M v = S C v = S_2 P_{S,MPI} S_1 C v = S_2 P_{S,MPI} C&#39; v\]
</p>
<p>. Again, if C was a coo matrix the simple way to obtain C' is replacing the row indices with the map \( g_1\).</p>
<p>Simplifications can be achieved if \( G_2 = S_2 = I\) is the identity or if \( P_{G,MPI} = P_{S,MPI} = P_{MPI}\) is symmetric, which means that in-place communication can be used.</p>
<dl class="section note"><dt>Note</dt><dd>Locally, a gather operation is trivially parallel but a scatter operation is not in general (because of the possible reduction operation).</dd></dl>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga05dfb8393768dc9fe68f8ae1baca2b68" name="ga05dfb8393768dc9fe68f8ae1baca2b68"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga05dfb8393768dc9fe68f8ae1baca2b68">&#9670;&#160;</a></span>mpi_gather()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class ContainerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void dg::mpi_gather </td>
          <td>(</td>
          <td class="paramtype">const thrust::host_vector&lt; std::array&lt; int, 2 &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>gather_map</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ContainerType &amp;</td>          <td class="paramname"><span class="paramname"><em>gatherFrom</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ContainerType &amp;</td>          <td class="paramname"><span class="paramname"><em>result</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm</td>          <td class="paramname"><span class="paramname"><em>comm</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Un-optimized distributed gather operation. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">ContainerType</td><td>A (host) vector </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">gather_map</td><td>Each element consists of <code>{rank within comm, local index on that rank}</code> pairs, which is equivalent to the global address of a vector element in <code>gatherFrom</code> </td></tr>
    <tr><td class="paramname">gatherFrom</td><td>Local part of the vector from which the calling and other ranks can gather indices </td></tr>
    <tr><td class="paramname">result</td><td>(Same size as gather_map on output) On output contains the elements that <code>gather_map</code> referenced </td></tr>
    <tr><td class="paramname">comm</td><td>The MPI communicator within which to exchange elements </td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#mpigather">MPI distributed gather and scatter operations</a> </dd></dl>

</div>
</div>
<a id="ga653c6729a09cef2106ef16e780e42a77" name="ga653c6729a09cef2106ef16e780e42a77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga653c6729a09cef2106ef16e780e42a77">&#9670;&#160;</a></span>mpi_invert_permutation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class Integer &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">thrust::host_vector&lt; std::array&lt; Integer, 2 &gt; &gt; dg::mpi_invert_permutation </td>
          <td>(</td>
          <td class="paramtype">const thrust::host_vector&lt; std::array&lt; Integer, 2 &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>p</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm</td>          <td class="paramname"><span class="paramname"><em>comm</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Invert a globally bijective index map. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">p</td><td>Each element consists of <code>{rank, local index on that rank}</code> pairs, which is equivalent to the global address of a vector element</td></tr>
  </table>
  </dd>
</dl>
<dl class="section attention"><dt>Attention</dt><dd>Must be bijective i.e. globally distinct elements in <code>toScatter</code> must map to distince elements in <code>result</code> and all elements in <code>result</code> must be mapped </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">comm</td><td>The MPI communicator within which to exchange elements </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>inverse map </dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#mpigather">MPI distributed gather and scatter operations</a> </dd></dl>

</div>
</div>
<a id="gaa0178080d1fb8f066a28e28e3b1465e1" name="gaa0178080d1fb8f066a28e28e3b1465e1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa0178080d1fb8f066a28e28e3b1465e1">&#9670;&#160;</a></span>mpi_permute()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class MessageType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt; int, MessageType &gt; dg::mpi_permute </td>
          <td>(</td>
          <td class="paramtype">const std::map&lt; int, MessageType &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>messages</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm</td>          <td class="paramname"><span class="paramname"><em>comm</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Exchange messages between processes in a communicator. </p>
<p>This happens in two communication phases (find more details in <a class="el" href="#mpi_dist_gather">MPI distributed gather and scatter</a>)</p><ol type="1">
<li>Call <code>MPI_Allgather</code> with given communicator to setup the communication pattern among processes</li>
<li>Call <code>MPI_Alltoallv</code> to send the actual messages.</li>
</ol>
<p>For example </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> rank, size;</div>
<div class="line">MPI_Comm_rank( MPI_COMM_WORLD, &amp;rank);</div>
<div class="line">MPI_Comm_size( MPI_COMM_WORLD, &amp;size);</div>
<div class="line"><span class="comment">// Send an integer to the next process in a &quot;circle&quot;</span></div>
<div class="line">std::map&lt;int, int&gt; messages = { {(rank + 1)%size, rank}};</div>
<div class="line">INFO( <span class="stringliteral">&quot;Rank &quot;</span>&lt;&lt;rank&lt;&lt;<span class="stringliteral">&quot; send message &quot;</span>&lt;&lt;messages[(rank+1)%size]&lt;&lt;<span class="stringliteral">&quot;\n&quot;</span>);</div>
<div class="line"><span class="keyword">auto</span> recv = <a class="code hl_function" href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a>( messages, MPI_COMM_WORLD);</div>
<div class="line"><span class="comment">// Each rank received a message from the previous rank</span></div>
<div class="line">INFO(<span class="stringliteral">&quot;Rank &quot;</span>&lt;&lt;rank&lt;&lt;<span class="stringliteral">&quot; received message &quot;</span>&lt;&lt;recv[(rank+size-1)%size]&lt;&lt;<span class="stringliteral">&quot;\n&quot;</span>);</div>
<div class="line">CHECK( recv[(rank+size-1)%size] == (rank+size-1)%  size);</div>
<div class="line"><span class="comment">// If we permute again we send everything back</span></div>
<div class="line"><span class="keyword">auto</span> messages_num = <a class="code hl_function" href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a>( recv, MPI_COMM_WORLD);</div>
<div class="line">CHECK( messages == messages_num);</div>
</div><!-- fragment --><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MessageType</td><td>Can be one of the following<ol type="1">
<li>A primitive type like <code>int</code> or <code>double</code> </li>
<li>A (host) vector of primitive types like <code>std::vector&lt;int&gt;</code> or <code>thrust::host_vector&lt;double&gt;</code> </li>
<li>A (host) vector of std::array of primitive types like <code>thrust::host_vector&lt;std::array&lt;double,3&gt;&gt;</code> </li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">messages</td><td>(in) <code>messages[rank]</code> contains the message that the calling process sends to the process rank within comm </td></tr>
    <tr><td class="paramname">comm</td><td>The MPI communicator within which to exchange messages. All processes in comm need to call this function. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>received_messages[rank]</code> contains the message that the calling process receveived from the process with rank in comm</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This can be used to bootstrap mpi gather operations if elements is an index map "recvIdx" of local indices of messages to receive from rank, because it "tells" every process which messages to send</dd>
<dd>
This function is a permutation i.e. <div class="fragment"><div class="line">recvIdx == <a class="code hl_function" href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a>( <a class="code hl_function" href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a>(recvIdx, comm), comm);</div>
<div class="ttc" id="agroup__mpi__comm_html_gaa0178080d1fb8f066a28e28e3b1465e1"><div class="ttname"><a href="#gaa0178080d1fb8f066a28e28e3b1465e1">dg::mpi_permute</a></div><div class="ttdeci">std::map&lt; int, MessageType &gt; mpi_permute(const std::map&lt; int, MessageType &gt; &amp;messages, MPI_Comm comm)</div><div class="ttdoc">Exchange messages between processes in a communicator.</div><div class="ttdef"><b>Definition</b> mpi_permutation.h:91</div></div>
</div><!-- fragment --> </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">ContainerType</td><td>Shared ContainerType. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#mpigather">MPI distributed gather and scatter operations</a> </dd>
<dd>
Also can be used <a class="el" href="group__time__utils.html#ga6da92394b084f50fdbfe42b13506ba40" title="Switch for the Timeloop integrate function.">to</a> <a class="el" href="group__invert.html#gad1a8bb330661c362436d659965fa436b" title="Compute inverse of square matrix (alias for dg::create::inverse)">invert</a> a bijective mpi gather map in <code><a class="el" href="#ga653c6729a09cef2106ef16e780e42a77" title="Invert a globally bijective index map.">dg::mpi_invert_permutation</a></code> </dd></dl>

</div>
</div>
<a id="ga7d13f26508e562519924d5c5950222c8" name="ga7d13f26508e562519924d5c5950222c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga7d13f26508e562519924d5c5950222c8">&#9670;&#160;</a></span>mpi_scatter()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class ContainerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void dg::mpi_scatter </td>
          <td>(</td>
          <td class="paramtype">const thrust::host_vector&lt; std::array&lt; int, 2 &gt; &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>scatter_map</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ContainerType &amp;</td>          <td class="paramname"><span class="paramname"><em>toScatter</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ContainerType &amp;</td>          <td class="paramname"><span class="paramname"><em>result</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm</td>          <td class="paramname"><span class="paramname"><em>comm</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>resize_result</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Un-optimized distributed scatter operation. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">ContainerType</td><td>A (host) vector </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">scatter_map</td><td>Each element consists of <code>{rank, local index on that rank}</code> pairs, which is equivalent to the global address of an element in <code>result</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="section attention"><dt>Attention</dt><dd>Must be injective i.e. globally distinct elements in <code>toScatter</code> must map to distince elements in <code>result</code> </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">toScatter</td><td>Same size as <code>scatter_map</code>. The <code>scatter_map</code> tells where each element in this vector is sent to </td></tr>
    <tr><td class="paramname">result</td><td>In principle we must know the size of <code>result</code> beforehand (because how else did you come up with a <code>scatter_map</code>) </td></tr>
    <tr><td class="paramname">comm</td><td>The MPI communicator within which to exchange elements </td></tr>
    <tr><td class="paramname">resize_result</td><td>If true we resize the result to the correct size (mainly needed for <code><a class="el" href="#ga653c6729a09cef2106ef16e780e42a77" title="Invert a globally bijective index map.">dg::mpi_invert_permutation</a></code>) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="#mpigather">MPI distributed gather and scatter operations</a> </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.9.3-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon Jun 23 2025 12:36:30 for Discontinuous Galerkin Library by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0 </li>
  </ul>
</div>
</body>
</html>
